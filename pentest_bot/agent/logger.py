import itertools
import logging
import textwrap
import threading
import enum
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple

from logger import LOG_DIR, get_console_handler, get_file_handler

class AgentLogLevels(str, enum.Enum):
    AGENT = "agent"
    FULL_REQUESTS = "full_requests"

LOG_PATH = Path(LOG_DIR)
LOG_NAME = "pentest_bot"
FULL_REQUEST_LOG_NAME = "full_requests"

INDENT_LEN = 100
INDENT_STR = ""
_run_lock = threading.Lock()           # <── thread-safety

class IndentFormatter(logging.Formatter):
	"""
	Wrap long messages and prepend a per-logger running index.

	Example output for two different loggers:

	    [1]: custom_agent.py:277 - Starting browser …
	    [2]: custom_agent.py:291 - Navigation succeeded
	        … (more agentlog lines)

	    [1]: http_client.py: 88 - >>> GET /index.html
	    [2]: http_client.py:121 - <<< 200 OK
	        … (more full_requests lines)
	"""

	def __init__(self, fmt: str = "", datefmt: Optional[str] = None) -> None:
		super().__init__(fmt, datefmt)

	def _next_idx(self, record: logging.LogRecord) -> int:
		"""
		Return the next counter value **for this logger only**.
		The counter is lazily created and stored on the Logger object.
		"""
		logger = logging.getLogger(record.name)
		if not hasattr(logger, "_log_counter"):
			logger._log_counter = itertools.count(1)	# type: ignore[attr-defined]
		return next(logger._log_counter)				# type: ignore[attr-defined]

	def format(self, record: logging.LogRecord) -> str:		# noqa: D401
		idx = self._next_idx(record)

		# Preserve your existing soft-wrap behaviour.
		wrapped: list[str] = []
		for para in record.getMessage().splitlines() or [""]:
			wrapped.extend(
				textwrap.wrap(
					para,
					width=INDENT_LEN,
					subsequent_indent=INDENT_STR,
					break_long_words=False,
					replace_whitespace=False,
				)
			)
		message = "\n".join(wrapped)

		# Assemble final line.
		return f"[{idx}]: {record.filename}:{record.lineno} - {message}"
# --------------------------------------------------------------------------- #
#  public API
# --------------------------------------------------------------------------- #
class _ThreadFilter(logging.Filter):
    """Accept records only from the thread that created this handler."""
    def __init__(self, thread_id: int):
        super().__init__()
        self._thread_id = thread_id

    def filter(self, record: logging.LogRecord) -> bool:          # noqa: D401
        return record.thread == self._thread_id                   # ❶ key line

def setup_agent_logger(
    eval_name: str,
    *,
    log_name: str = LOG_NAME,
    subfolder: str = "",
    name: AgentLogLevels = AgentLogLevels.AGENT,
    level: int = logging.INFO,
) -> Tuple[logging.Logger, logging.Logger]:
    """
    Logger that supports simultaneously logging two levels of log density to file
    """
    # ─────────── Primary (“agentlog”) logger ────────────
    logger = logging.getLogger(name)
    logger.setLevel(level)

    if not any(isinstance(h, logging.StreamHandler) for h in logger.handlers):
        logger.addHandler(get_console_handler())

    if not hasattr(logger, "_run_dir"):
        with _run_lock:
            if not hasattr(logger, "_run_dir"):
                base_dir = LOG_PATH / log_name
                full_dir = (
                    base_dir / subfolder
                    if subfolder
                    else base_dir / datetime.now().strftime("%Y-%m-%d")
                )
                full_dir.mkdir(parents=True, exist_ok=True)
                run_id = max(
                    (int(p.name) for p in full_dir.iterdir()
                     if p.is_dir() and p.name.isdigit()),
                    default=-1,
                ) + 1
                run_dir = full_dir / str(run_id)
                run_dir.mkdir()
                logger._run_dir = run_dir                       # type: ignore[attr-defined]

    run_dir: Path = logger._run_dir                             # type: ignore[attr-defined]
    thread_id = threading.get_ident()

    if not any(
        isinstance(h, logging.FileHandler) and getattr(h, "_thread_id", None) == thread_id
        for h in logger.handlers
    ):
        log_file = run_dir / f"{eval_name}.log"
        fh = get_file_handler(log_file)
        fh._thread_id = thread_id                                # type: ignore[attr-defined]
        fh.addFilter(_ThreadFilter(thread_id))
        fh.setFormatter(
            IndentFormatter(
                "%(asctime)s - %(name)s:%(levelname)s: "
                "%(filename)s:%(lineno)d - %(wrapped_msg)s",
                datefmt="%Y-%m-%d %H:%M:%S",
            )
        )
        logger.addHandler(fh)

    # ─────────── Secondary (“full_requests”) logger ──────
    fr_logger = logging.getLogger(AgentLogLevels.FULL_REQUESTS.value)
    fr_logger.setLevel(level)
    fr_logger.propagate = False  # prevent double printing to parent

    # console stream once (optional – comment out if not desired)
    if not any(isinstance(h, logging.StreamHandler) for h in fr_logger.handlers):
        fr_logger.addHandler(get_console_handler())

    # ensure sub-directory …/full_requests/
    full_req_dir = run_dir / AgentLogLevels.FULL_REQUESTS.value
    full_req_dir.mkdir(exist_ok=True)

    if not any(
        isinstance(h, logging.FileHandler) and getattr(h, "_thread_id", None) == thread_id
        for h in fr_logger.handlers
    ):
        fr_log_file = full_req_dir / f"{eval_name}_requests.log"
        fr_fh = get_file_handler(fr_log_file)
        fr_fh._thread_id = thread_id                             # type: ignore[attr-defined]
        fr_fh.addFilter(_ThreadFilter(thread_id))
        fr_fh.setFormatter(
            IndentFormatter(
                "%(asctime)s - %(name)s:%(levelname)s: "
                "%(filename)s:%(lineno)d - %(wrapped_msg)s",
                datefmt="%Y-%m-%d %H:%M:%S",
            )
        )
        fr_logger.addHandler(fr_fh)

    return logger, fr_logger